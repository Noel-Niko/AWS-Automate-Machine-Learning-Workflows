{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noel-Niko/AWS-Automate-Machine-Learning-Workflows/blob/master/use-cases/ODSC-Workshop/ODSC_Synthetic_Data_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Build Synthetic Datasets with Cerebras + Synthetic Data Kit\n",
        "\n",
        "Checkout: Synthetic-Data-Kit here: https://github.com/meta-llama/synthetic-data-kit/\n",
        "\n",
        "**ODSC Workshop - From Research Paper to Fine-Tuning Dataset**\n",
        "\n",
        "In this notebook, you'll:\n",
        "- ‚úÖ Parse the Llama 3 research paper\n",
        "- ‚úÖ Generate 50+ Q&A pairs using Cerebras inference\n",
        "- ‚úÖ Filter for quality using LLM-as-judge\n",
        "- ‚úÖ Export to fine-tuning format\n",
        "\n",
        "**No coding required - just run the cells!** ‚ö°"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîë Step 1: Set Your Cerebras API Key\n",
        "\n",
        "Enter your Cerebras API key below:"
      ],
      "metadata": {
        "id": "api_key_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Option 1: Enter your API key directly (not recommended for sharing)\n",
        "CEREBRAS_API_KEY = \"csk-3wfykep3w3trydreemye6wyk4mwcrvnkwv5wcm8m88wjhxw5\"\n",
        "\n",
        "# Option 2: Use Colab Secrets (recommended - add key as 'CEREBRAS_API_KEY' in secrets)\n",
        "# Uncomment below if using secrets:\n",
        "# CEREBRAS_API_KEY = userdata.get('CEREBRAS_API_KEY')\n",
        "\n",
        "# Set environment variable\n",
        "os.environ['CEREBRAS_API_KEY'] = CEREBRAS_API_KEY\n",
        "\n",
        "print(\"‚úÖ API key configured!\")\n",
        "print(f\"üîë Key preview: {CEREBRAS_API_KEY[:10]}...\")"
      ],
      "metadata": {
        "id": "api_key_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Step 2: Install Synthetic Data Kit\n",
        "\n",
        "Installing the toolkit and dependencies..."
      ],
      "metadata": {
        "id": "install_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q synthetic-data-kit\n",
        "!pip install -q datasets  # For HuggingFace format export\n",
        "\n",
        "# Verify installation\n",
        "!synthetic-data-kit --help | head -15\n",
        "\n",
        "print(\"\\n‚úÖ Installation complete!\")"
      ],
      "metadata": {
        "id": "install_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è Step 3: Download Workshop Configuration\n",
        "\n",
        "Downloading the ready-to-use config from GitHub and setting up directories..."
      ],
      "metadata": {
        "id": "setup_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory structure\n",
        "!mkdir -p data/{parsed,generated,curated,final}\n",
        "\n",
        "print(\"üì• Downloading workshop config from GitHub...\")\n",
        "\n",
        "# Download the ready-to-use config from GitHub (ODSC-Workshop branch)\n",
        "!wget -q https://raw.githubusercontent.com/meta-llama/synthetic-data-kit/ODSC-Workshop/configs/config.yaml -O cerebras_config.yaml\n",
        "\n",
        "print(\"‚úÖ Config downloaded!\")\n",
        "\n",
        "# Replace the API key placeholder with your actual key\n",
        "import os\n",
        "\n",
        "with open('cerebras_config.yaml', 'r') as f:\n",
        "    config_content = f.read()\n",
        "\n",
        "# Replace the placeholder with actual API key\n",
        "config_content = config_content.replace('YOUR_CEREBRAS_API_KEY', os.environ.get('CEREBRAS_API_KEY'))\n",
        "\n",
        "with open('cerebras_config.yaml', 'w') as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "print(\"‚úÖ Configuration ready with your API key!\")\n",
        "print(\"\\nüìÅ Directory structure:\")\n",
        "!tree data/ || ls -R data/\n",
        "\n",
        "print(\"\\nüìÑ Config preview (first 35 lines):\")\n",
        "!head -35 cerebras_config.yaml"
      ],
      "metadata": {
        "id": "setup_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîå Step 4: Test API Connection\n",
        "\n",
        "Verifying connection to Cerebras..."
      ],
      "metadata": {
        "id": "test_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!synthetic-data-kit -c cerebras_config.yaml system-check\n",
        "\n",
        "print(\"\\n‚úÖ If you see 'API endpoint access confirmed' above, you're ready to go!\")"
      ],
      "metadata": {
        "id": "test_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• Step 5: Download Llama 3 Paper\n",
        "\n",
        "Downloading the research paper from arXiv..."
      ],
      "metadata": {
        "id": "download_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://arxiv.org/pdf/2407.21783 -O llama3_paper.pdf\n",
        "\n",
        "# Verify download\n",
        "import os\n",
        "file_size = os.path.getsize('llama3_paper.pdf') / 1024  # KB\n",
        "\n",
        "print(f\"‚úÖ Paper downloaded successfully!\")\n",
        "print(f\"üìÑ File: llama3_paper.pdf\")\n",
        "print(f\"üíæ Size: {file_size:.1f} KB\")\n",
        "\n",
        "!ls -lh llama3_paper.pdf"
      ],
      "metadata": {
        "id": "download_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üîÑ The 4-Stage Pipeline\n",
        "\n",
        "```\n",
        "PDF ‚Üí INGEST ‚Üí CREATE ‚Üí CURATE ‚Üí SAVE-AS ‚Üí Training Data ‚ú®\n",
        "```"
      ],
      "metadata": {
        "id": "pipeline_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Stage 1: INGEST - Parse the PDF\n",
        "\n",
        "**What it does:** Extracts clean text from the PDF and saves as .txt\n",
        "\n",
        "This takes ~30-60 seconds..."
      ],
      "metadata": {
        "id": "ingest_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  ingest llama3_paper.pdf\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ INGEST complete!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check output\n",
        "!ls -lh data/parsed/\n",
        "\n",
        "# Preview first few lines of the extracted text\n",
        "print(\"\\nüìù Preview of extracted text:\")\n",
        "!head -20 data/parsed/llama3_paper.txt"
      ],
      "metadata": {
        "id": "ingest_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü§ñ Stage 2: CREATE - Generate Q&A Pairs\n",
        "\n",
        "**What it does:** Uses Cerebras + Llama 3.3-70B with custom prompts to generate intelligent Q&A pairs\n",
        "\n",
        "This takes ~2-4 minutes for 50 pairs... ‚òï"
      ],
      "metadata": {
        "id": "create_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  create data/parsed/llama3_paper.txt \\\n",
        "  --type qa \\\n",
        "  --num-pairs 50 \\\n",
        "  --verbose\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ CREATE complete!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check output\n",
        "!ls -lh data/generated/\n",
        "\n",
        "# Count Q&A pairs\n",
        "import json\n",
        "with open('data/generated/llama3_paper_qa_pairs.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"\\nüìä Generated {len(data['qa_pairs'])} Q&A pairs\")"
      ],
      "metadata": {
        "id": "create_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîç Preview Generated Q&A Pairs"
      ],
      "metadata": {
        "id": "preview_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load and display first 3 Q&A pairs\n",
        "with open('data/generated/llama3_paper_qa_pairs.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(\"üìù Summary:\")\n",
        "print(data['summary'][:200] + \"...\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìö Sample Q&A Pairs:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, pair in enumerate(data['qa_pairs'][:3], 1):\n",
        "    print(f\"\\n{i}. Question:\")\n",
        "    print(f\"   {pair['question']}\")\n",
        "    print(f\"\\n   Answer:\")\n",
        "    print(f\"   {pair['answer'][:150]}...\")\n",
        "    print(\"\\n\" + \"-\"*60)"
      ],
      "metadata": {
        "id": "preview_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ú® Stage 3: CURATE - Filter Quality\n",
        "\n",
        "**What it does:** Uses LLM-as-judge with custom rating prompt to rate and filter Q&A pairs\n",
        "\n",
        "This takes ~2-3 minutes... üéØ"
      ],
      "metadata": {
        "id": "curate_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  curate data/generated/llama3_paper_qa_pairs.json \\\n",
        "  --threshold 7.5 \\\n",
        "  --verbose\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ CURATE complete!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check output\n",
        "!ls -lh data/curated/"
      ],
      "metadata": {
        "id": "curate_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìä Quality Metrics"
      ],
      "metadata": {
        "id": "metrics_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load curated data\n",
        "with open('data/curated/llama3_paper_qa_pairs_cleaned.json', 'r') as f:\n",
        "    curated = json.load(f)\n",
        "\n",
        "metrics = curated.get('metrics', {})\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä CURATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüìù Total pairs generated:     {metrics.get('total', 0)}\")\n",
        "print(f\"‚úÖ Pairs kept (‚â•7.5 rating):  {metrics.get('filtered', 0)}\")\n",
        "print(f\"üìà Retention rate:            {metrics.get('retention_rate', 0)*100:.1f}%\")\n",
        "print(f\"‚≠ê Average quality score:     {metrics.get('avg_score', 0):.1f}/10\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ Quality filtering complete!\")\n",
        "print(f\"   Kept {metrics.get('filtered', 0)} high-quality pairs\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "metrics_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üëÄ Preview Top-Rated Q&A Pairs"
      ],
      "metadata": {
        "id": "preview_curated_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('data/curated/llama3_paper_qa_pairs_cleaned.json', 'r') as f:\n",
        "    curated = json.load(f)\n",
        "\n",
        "# Sort by rating (descending)\n",
        "sorted_pairs = sorted(curated['qa_pairs'], key=lambda x: x.get('rating', 0), reverse=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üåü TOP 3 HIGHEST-RATED Q&A PAIRS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, pair in enumerate(sorted_pairs[:3], 1):\n",
        "    print(f\"\\n{i}. Rating: ‚≠ê {pair.get('rating', 'N/A')}/10\")\n",
        "    print(f\"\\n   Q: {pair['question']}\")\n",
        "    print(f\"\\n   A: {pair['answer'][:200]}...\")\n",
        "    print(\"\\n\" + \"-\"*60)"
      ],
      "metadata": {
        "id": "preview_curated_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Stage 4: SAVE-AS - Export to Training Format\n",
        "\n",
        "**What it does:** Converts to fine-tuning ready formats\n",
        "\n",
        "We'll create multiple formats..."
      ],
      "metadata": {
        "id": "save_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Format 1: HuggingFace Dataset (Arrow format - recommended!)\n",
        "print(\"üì¶ Creating HuggingFace dataset...\")\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  save-as data/curated/llama3_paper_qa_pairs_cleaned.json \\\n",
        "  --format ft \\\n",
        "  --storage hf\n",
        "\n",
        "# Format 2: OpenAI Fine-Tuning (JSON)\n",
        "print(\"\\nüì¶ Creating OpenAI FT format...\")\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  save-as data/curated/llama3_paper_qa_pairs_cleaned.json \\\n",
        "  --format ft\n",
        "\n",
        "# Format 3: Alpaca format\n",
        "print(\"\\nüì¶ Creating Alpaca format...\")\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  save-as data/curated/llama3_paper_qa_pairs_cleaned.json \\\n",
        "  --format alpaca\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ SAVE-AS complete!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Show all formats\n",
        "!ls -lh data/final/"
      ],
      "metadata": {
        "id": "save_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ Load & Inspect HuggingFace Dataset"
      ],
      "metadata": {
        "id": "inspect_hf_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "import json\n",
        "\n",
        "# Load the HuggingFace dataset\n",
        "dataset = load_from_disk('data/final/llama3_paper_qa_pairs_cleaned_ft_hf')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìä HUGGINGFACE DATASET INFO\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüì¶ Dataset size: {len(dataset)} examples\")\n",
        "print(f\"\\nüîß Features: {dataset.features}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìù SAMPLE TRAINING EXAMPLE (OpenAI Format)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Show first example\n",
        "example = dataset[0]\n",
        "print(json.dumps(example, indent=2))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Ready to use with Transformers, Axolotl, or any training framework!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "inspect_hf_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üéâ Success! Your Dataset is Ready!\n",
        "\n",
        "## üìä Final Summary"
      ],
      "metadata": {
        "id": "summary_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import load_from_disk\n",
        "\n",
        "# Load files\n",
        "with open('data/generated/llama3_paper_qa_pairs.json', 'r') as f:\n",
        "    generated = json.load(f)\n",
        "\n",
        "with open('data/curated/llama3_paper_qa_pairs_cleaned.json', 'r') as f:\n",
        "    curated = json.load(f)\n",
        "\n",
        "dataset = load_from_disk('data/final/llama3_paper_qa_pairs_cleaned_ft_hf')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ WORKSHOP COMPLETE - SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüìö Source:\")\n",
        "print(\"   ‚Ä¢ Llama 3 Research Paper (arXiv:2407.21783)\")\n",
        "\n",
        "print(\"\\nüîÑ Pipeline Results:\")\n",
        "print(f\"   1Ô∏è‚É£ INGEST:   ‚úÖ PDF ‚Üí Clean text (.txt)\")\n",
        "print(f\"   2Ô∏è‚É£ CREATE:   ‚úÖ Generated {len(generated['qa_pairs'])} Q&A pairs (custom prompts)\")\n",
        "print(f\"   3Ô∏è‚É£ CURATE:   ‚úÖ Kept {len(curated['qa_pairs'])} high-quality pairs (‚â•7.5/10)\")\n",
        "print(f\"   4Ô∏è‚É£ SAVE-AS:  ‚úÖ Exported to 3 formats\")\n",
        "\n",
        "metrics = curated.get('metrics', {})\n",
        "print(\"\\nüìä Quality Metrics:\")\n",
        "print(f\"   ‚Ä¢ Retention rate: {metrics.get('retention_rate', 0)*100:.1f}%\")\n",
        "print(f\"   ‚Ä¢ Average score: {metrics.get('avg_score', 0):.1f}/10\")\n",
        "\n",
        "print(\"\\nüíæ Output Formats:\")\n",
        "print(f\"   ‚Ä¢ HuggingFace Dataset: {len(dataset)} examples (Arrow format)\")\n",
        "print(f\"   ‚Ä¢ OpenAI Fine-Tuning: JSON format\")\n",
        "print(f\"   ‚Ä¢ Alpaca: JSON format\")\n",
        "\n",
        "print(\"\\nüìÇ Files Location:\")\n",
        "print(\"   ‚Ä¢ data/final/ (all formats)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ Your dataset is ready for fine-tuning!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüí° Next Steps:\")\n",
        "print(\"   ‚Ä¢ Download the dataset from data/final/\")\n",
        "print(\"   ‚Ä¢ Use with Transformers, Axolotl, or your training framework\")\n",
        "print(\"   ‚Ä¢ Fine-tune your model!\")"
      ],
      "metadata": {
        "id": "summary_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üéÆ Bonus Experiments\n",
        "\n",
        "Try these optional experiments to explore more features!"
      ],
      "metadata": {
        "id": "experiments_section"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Experiment 1: Try Different Quality Thresholds"
      ],
      "metadata": {
        "id": "exp1_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Strict filtering (8.5+)\n",
        "print(\"üîç Testing threshold 8.5 (very strict)...\")\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  curate data/generated/llama3_paper_qa_pairs.json \\\n",
        "  --threshold 8.5 \\\n",
        "  -o data/curated/strict_8.5.json\n",
        "\n",
        "# Lenient filtering (6.5+)\n",
        "print(\"\\nüîç Testing threshold 6.5 (lenient)...\")\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  curate data/generated/llama3_paper_qa_pairs.json \\\n",
        "  --threshold 6.5 \\\n",
        "  -o data/curated/lenient_6.5.json\n",
        "\n",
        "# Compare results\n",
        "with open('data/curated/strict_8.5.json') as f:\n",
        "    strict = json.load(f)\n",
        "with open('data/curated/lenient_6.5.json') as f:\n",
        "    lenient = json.load(f)\n",
        "with open('data/curated/llama3_paper_qa_pairs_cleaned.json') as f:\n",
        "    default = json.load(f)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä THRESHOLD COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nThreshold 8.5 (strict):   {len(strict['qa_pairs'])} pairs kept\")\n",
        "print(f\"Threshold 7.5 (default):  {len(default['qa_pairs'])} pairs kept\")\n",
        "print(f\"Threshold 6.5 (lenient):  {len(lenient['qa_pairs'])} pairs kept\")\n",
        "print(\"\\nüí° Lower threshold = more pairs, but potentially lower quality\")"
      ],
      "metadata": {
        "id": "exp1_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Experiment 2: Generate More Q&A Pairs"
      ],
      "metadata": {
        "id": "exp2_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print(\"üéØ Generating 100 Q&A pairs...\\n\")\n",
        "\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  create data/parsed/llama3_paper.txt \\\n",
        "  --type qa \\\n",
        "  --num-pairs 100 \\\n",
        "  -o data/generated/large_dataset.json \\\n",
        "  --verbose\n",
        "\n",
        "# Count pairs\n",
        "import json\n",
        "with open('data/generated/large_dataset.json') as f:\n",
        "    large = json.load(f)\n",
        "\n",
        "print(f\"\\n‚úÖ Generated {len(large['qa_pairs'])} Q&A pairs!\")\n",
        "print(\"\\nüí° You can now curate this larger dataset with:\")\n",
        "print(\"   synthetic-data-kit curate data/generated/large_dataset.json\")"
      ],
      "metadata": {
        "id": "exp2_cell",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "215001f9-42ea-4661-cc98-f50ecdb0d351"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:09\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 260\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 51 (total: 51/100)\n",
            "\u001b[2KParsing response of length 234\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 52 (total: 52/100)\n",
            "\u001b[2KParsing response of length 172\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 53 (total: 53/100)\n",
            "\u001b[2KParsing response of length 206\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 54 (total: 54/100)\n",
            "\u001b[2KParsing response of length 257\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 55 (total: 55/100)\n",
            "\u001b[2KProcessing batch 12/23 with 5 chunks\n",
            "\u001b[32m‚†¶\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:synthetic_data_kit.models.llm_client:Processing batch 1/1 with 5 requests\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 151\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 56 (total: 56/100)\n",
            "\u001b[2KParsing response of length 166\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 57 (total: 57/100)\n",
            "\u001b[2KParsing response of length 327\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 58 (total: 58/100)\n",
            "\u001b[2KParsing response of length 135\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 59 (total: 59/100)\n",
            "\u001b[2KParsing response of length 285\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 60 (total: 60/100)\n",
            "\u001b[2KProcessing batch 13/23 with 5 chunks\n",
            "\u001b[32m‚†¥\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:synthetic_data_kit.models.llm_client:Processing batch 1/1 with 5 requests\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-261' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-262' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-263' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-264' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-265' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-266' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-267' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-268' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-269' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-270' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-271' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-272' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-273' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-274' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-275' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:10\u001b[0m \u001b[36m-:--:--\u001b[0mERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-276' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-277' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-278' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-279' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-280' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-281' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-282' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:10\u001b[0m \u001b[36m-:--:--\u001b[0mERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-283' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-284' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-285' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.12/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/streams/tls.py\", line 234, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 1323, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 1213, in close\n",
            "    super().close()\n",
            "  File \"/usr/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 799, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:11\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 130\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 61 (total: 61/100)\n",
            "\u001b[2KParsing response of length 188\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 62 (total: 62/100)\n",
            "\u001b[2KParsing response of length 231\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 63 (total: 63/100)\n",
            "\u001b[2KParsing response of length 191\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 64 (total: 64/100)\n",
            "\u001b[2KParsing response of length 203\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 65 (total: 65/100)\n",
            "\u001b[2KProcessing batch 14/23 with 5 chunks\n",
            "\u001b[32m‚†ß\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:synthetic_data_kit.models.llm_client:Processing batch 1/1 with 5 requests\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:12\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 140\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 66 (total: 66/100)\n",
            "\u001b[2KParsing response of length 142\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 67 (total: 67/100)\n",
            "\u001b[2KParsing response of length 223\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 68 (total: 68/100)\n",
            "\u001b[2KParsing response of length 111\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 69 (total: 69/100)\n",
            "\u001b[2KParsing response of length 184\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 70 (total: 70/100)\n",
            "\u001b[2KProcessing batch 15/23 with 5 chunks\n",
            "\u001b[32m‚†¶\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:synthetic_data_kit.models.llm_client:Processing batch 1/1 with 5 requests\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:13\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 254\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 71 (total: 71/100)\n",
            "\u001b[2KParsing response of length 193\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 72 (total: 72/100)\n",
            "\u001b[2KParsing response of length 175\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 73 (total: 73/100)\n",
            "\u001b[2KParsing response of length 122\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 74 (total: 74/100)\n",
            "\u001b[2KParsing response of length 125\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 75 (total: 75/100)\n",
            "\u001b[2KProcessing batch 16/23 with 5 chunks\n",
            "\u001b[32m‚†º\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:synthetic_data_kit.models.llm_client:Processing batch 1/1 with 5 requests\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:13\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 144\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 76 (total: 76/100)\n",
            "\u001b[2KParsing response of length 120\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 77 (total: 77/100)\n",
            "\u001b[2KParsing response of length 214\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 78 (total: 78/100)\n",
            "\u001b[2KParsing response of length 131\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 79 (total: 79/100)\n",
            "\u001b[2KParsing response of length 138\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 80 (total: 80/100)\n",
            "\u001b[2KProcessing batch 17/23 with 5 chunks\n",
            "\u001b[32m‚†π\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:synthetic_data_kit.models.llm_client:Processing batch 1/1 with 5 requests\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:14\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:14\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 122\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 81 (total: 81/100)\n",
            "\u001b[2KParsing response of length 140\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 82 (total: 82/100)\n",
            "\u001b[2KParsing response of length 171\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 83 (total: 83/100)\n",
            "\u001b[2KParsing response of length 219\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 84 (total: 84/100)\n",
            "\u001b[2KParsing response of length 201\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 85 (total: 85/100)\n",
            "\u001b[2KProcessing batch 18/23 with 5 chunks\n",
            "\u001b[32m‚†∏\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:synthetic_data_kit.models.llm_client:Processing batch 1/1 with 5 requests\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:15\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:15\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 233\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 86 (total: 86/100)\n",
            "\u001b[2KParsing response of length 177\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 87 (total: 87/100)\n",
            "\u001b[2KParsing response of length 116\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 88 (total: 88/100)\n",
            "\u001b[2KParsing response of length 178\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 89 (total: 89/100)\n",
            "\u001b[2KParsing response of length 214\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 90 (total: 90/100)\n",
            "\u001b[2KProcessing batch 19/23 with 5 chunks\n",
            "\u001b[32m‚†π\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:synthetic_data_kit.models.llm_client:Processing batch 1/1 with 5 requests\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:16\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 136\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 91 (total: 91/100)\n",
            "\u001b[2KParsing response of length 238\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 92 (total: 92/100)\n",
            "\u001b[2KParsing response of length 200\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 93 (total: 93/100)\n",
            "\u001b[2KParsing response of length 178\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 94 (total: 94/100)\n",
            "\u001b[2KParsing response of length 193\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 95 (total: 95/100)\n",
            "\u001b[2KProcessing batch 20/23 with 5 chunks\n",
            "\u001b[32m‚†∏\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:synthetic_data_kit.models.llm_client:Processing batch 1/1 with 5 requests\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:17\u001b[0m \u001b[36m-:--:--\u001b[0mINFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:synthetic_data_kit.models.llm_client:Received response from api-endpoint\n",
            "\u001b[2KParsing response of length 188\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 96 (total: 96/100)\n",
            "\u001b[2KParsing response of length 200\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 97 (total: 97/100)\n",
            "\u001b[2KParsing response of length 143\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 98 (total: 98/100)\n",
            "\u001b[2KParsing response of length 201\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 99 (total: 99/100)\n",
            "\u001b[2KParsing response of length 174\n",
            "\u001b[2KSuccessfully parsed 1 QA pairs\n",
            "\u001b[2K  Generated 1 pairs from chunk 100 (total: 100/100)\n",
            "\u001b[2KGenerating QA pairs \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[33m0:00:17\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
            "\u001b[2KGenerated 100 QA pairs total (requested: 100)\n",
            "\u001b[2KSaving result to data/generated/large_dataset.json/llama3_paper_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to \n",
            "data/generated/large_dataset.json/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to \n",
            "data/generated/large_dataset.json/llama3_paper_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m‚úÖ Content saved to \u001b[0m\u001b[1;32mdata/generated/large_dataset.json/llama3_paper_qa_pairs.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: 'data/generated/large_dataset.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'data/generated/large_dataset.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Experiment 3: Different Chunking Strategies"
      ],
      "metadata": {
        "id": "exp3_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Small chunks (more granular)\n",
        "print(\"üìè Testing small chunks (2000 chars)...\\n\")\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  create data/parsed/llama3_paper.txt \\\n",
        "  --type qa \\\n",
        "  --num-pairs 20 \\\n",
        "  --chunk-size 2000 \\\n",
        "  --chunk-overlap 100 \\\n",
        "  -o data/generated/small_chunks.json\n",
        "\n",
        "# Large chunks (more context)\n",
        "print(\"\\nüìè Testing large chunks (6000 chars)...\\n\")\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  create data/parsed/llama3_paper.txt \\\n",
        "  --type qa \\\n",
        "  --num-pairs 20 \\\n",
        "  --chunk-size 6000 \\\n",
        "  --chunk-overlap 300 \\\n",
        "  -o data/generated/large_chunks.json\n",
        "\n",
        "# Compare questions\n",
        "with open('data/generated/small_chunks.json') as f:\n",
        "    small = json.load(f)\n",
        "with open('data/generated/large_chunks.json') as f:\n",
        "    large = json.load(f)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä CHUNKING COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüî¨ Small Chunks (2000 chars) - Sample Question:\")\n",
        "print(f\"   {small['qa_pairs'][0]['question']}\")\n",
        "\n",
        "print(\"\\nüìö Large Chunks (6000 chars) - Sample Question:\")\n",
        "print(f\"   {large['qa_pairs'][0]['question']}\")\n",
        "\n",
        "print(\"\\nüí° Small chunks = more specific questions\")\n",
        "print(\"üí° Large chunks = more context-aware questions\")"
      ],
      "metadata": {
        "id": "exp3_cell",
        "outputId": "aa6d8b65-6987-4042-d622-bd190c366ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìè Testing small chunks (2000 chars)...\n",
            "\n",
            "Loading config from: /usr/local/lib/python3.12/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: /usr/local/lib/python3.12/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: cerebras_config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "\u001b[32müîó Using api-endpoint provider\u001b[0m\n",
            "\u001b[?25lLoading config from: cerebras_config.yaml\n",
            "\u001b[2KConfig has LLM provider set to: api-endpoint\n",
            "\u001b[2KAPI_ENDPOINT_KEY from environment: Not found\n",
            "\u001b[2KUsing API key: From config\n",
            "\u001b[2KUsing API base URL: https://api.cerebras.ai/v1\n",
            "\u001b[2KL Using api-endpoint provider\n",
            "\u001b[2KLoading config from: cerebras_config.yaml\n",
            "\u001b[2KConfig has LLM provider set to: api-endpoint\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2KProcessing 113 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†¶\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 20 QA pairs total (requested: 20)\n",
            "\u001b[2KSaving result to data/generated/small_chunks.json/llama3_paper_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/small_chunks.json/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to \n",
            "data/generated/small_chunks.json/llama3_paper_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m‚úÖ Content saved to \u001b[0m\u001b[1;32mdata/generated/small_chunks.json/llama3_paper_qa_pairs.json\u001b[0m\n",
            "\n",
            "üìè Testing large chunks (6000 chars)...\n",
            "\n",
            "Loading config from: /usr/local/lib/python3.12/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: /usr/local/lib/python3.12/dist-packages/synthetic_data_kit/config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "Loading config from: cerebras_config.yaml\n",
            "Config has LLM provider set to: api-endpoint\n",
            "get_llm_provider returning: api-endpoint\n",
            "\u001b[32müîó Using api-endpoint provider\u001b[0m\n",
            "\u001b[?25lLoading config from: cerebras_config.yaml\n",
            "\u001b[2KConfig has LLM provider set to: api-endpoint\n",
            "\u001b[2KAPI_ENDPOINT_KEY from environment: Not found\n",
            "\u001b[2KUsing API key: From config\n",
            "\u001b[2KUsing API base URL: https://api.cerebras.ai/v1\n",
            "\u001b[2KL Using api-endpoint provider\n",
            "\u001b[2KLoading config from: cerebras_config.yaml\n",
            "\u001b[2KConfig has LLM provider set to: api-endpoint\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2KProcessing 113 chunks to generate QA pairs...\n",
            "\u001b[2K\u001b[32m‚†ã\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†∏\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†¥\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†ô\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†π\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†º\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†ß\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2K\u001b[32m‚†á\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...INFO:httpx:HTTP Request: POST https://api.cerebras.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[2KBatch processing complete.\n",
            "\u001b[2KGenerated 20 QA pairs total (requested: 20)\n",
            "\u001b[2KSaving result to data/generated/large_chunks.json/llama3_paper_qa_pairs.json\n",
            "\u001b[2KSuccessfully wrote test file to data/generated/large_chunks.json/test_write.json\n",
            "\u001b[2KSuccessfully wrote result to \n",
            "data/generated/large_chunks.json/llama3_paper_qa_pairs.json\n",
            "\u001b[2K\u001b[32m‚†è\u001b[0m Generating qa content from data/parsed/llama3_paper.txt...\n",
            "\u001b[1A\u001b[2K\u001b[32m‚úÖ Content saved to \u001b[0m\u001b[1;32mdata/generated/large_chunks.json/llama3_paper_qa_pairs.json\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: 'data/generated/small_chunks.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4250740819.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Compare questions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/generated/small_chunks.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msmall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/generated/large_chunks.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'data/generated/small_chunks.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Experiment 4: Chain-of-Thought Enhancement\n",
        "\n",
        "**Advanced:** Add reasoning steps to your Q&A pairs using custom CoT prompts!"
      ],
      "metadata": {
        "id": "exp4_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create CoT config with custom enhancement prompt\n",
        "cot_config = f\"\"\"llm:\n",
        "  provider: \"api-endpoint\"\n",
        "\n",
        "api-endpoint:\n",
        "  api_base: \"https://api.cerebras.ai/v1\"\n",
        "  api_key: \"{os.environ.get('CEREBRAS_API_KEY')}\"\n",
        "  model: \"llama3.3-70b\"\n",
        "\n",
        "generation:\n",
        "  temperature: 0.2\n",
        "  max_tokens: 8192\n",
        "\n",
        "prompts:\n",
        "  cot_enhancement: |\n",
        "    You are enhancing Q&A conversations by adding step-by-step reasoning.\n",
        "\n",
        "    For each assistant response, add detailed reasoning BEFORE the answer:\n",
        "\n",
        "    Transform:\n",
        "    Q: \"What is Llama 3's context length?\"\n",
        "    A: \"128K tokens\"\n",
        "\n",
        "    Into:\n",
        "    Q: \"What is Llama 3's context length?\"\n",
        "    A: \"Let me break this down:\n",
        "    Step 1: Looking at the architecture section...\n",
        "    Step 2: The paper states...\n",
        "    Therefore: Llama 3 supports 128K tokens\"\n",
        "\n",
        "    Enhance these conversations:\n",
        "    {{{{conversations}}}}\n",
        "\"\"\"\n",
        "\n",
        "with open('cot_config.yaml', 'w') as f:\n",
        "    f.write(cot_config)\n",
        "\n",
        "print(\"‚úÖ CoT config created with custom enhancement prompt!\\n\")\n",
        "\n",
        "# Step 2: Generate simple Q&A\n",
        "print(\"üìù Generating 10 simple Q&A pairs...\\n\")\n",
        "!synthetic-data-kit -c cerebras_config.yaml \\\n",
        "  create data/parsed/llama3_paper.txt \\\n",
        "  --type qa \\\n",
        "  --num-pairs 10 \\\n",
        "  -o data/generated/simple_for_cot.json\n",
        "\n",
        "# Step 3: Add reasoning\n",
        "print(\"\\nüß† Adding Chain-of-Thought reasoning...\\n\")\n",
        "!synthetic-data-kit -c cot_config.yaml \\\n",
        "  create data/generated/simple_for_cot.json \\\n",
        "  --type cot-enhance \\\n",
        "  -o data/generated/with_reasoning.json \\\n",
        "  --verbose\n",
        "\n",
        "print(\"\\n‚úÖ Chain-of-Thought enhancement complete!\")"
      ],
      "metadata": {
        "id": "exp4_cell_setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Compare before and after\n",
        "with open('data/generated/simple_for_cot.json') as f:\n",
        "    before = json.load(f)\n",
        "with open('data/generated/with_reasoning.json') as f:\n",
        "    after = json.load(f)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üîç CHAIN-OF-THOUGHT COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get first Q&A from conversations\n",
        "before_conv = before['qa_pairs'][0]\n",
        "after_conv = after[0]['conversations'] if isinstance(after, list) else after['conversations'][0]\n",
        "\n",
        "print(\"\\nüìù BEFORE (Simple answer):\")\n",
        "print(f\"Q: {before_conv['question']}\")\n",
        "print(f\"A: {before_conv['answer'][:150]}...\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "\n",
        "print(\"\\nüß† AFTER (With reasoning):\")\n",
        "for msg in after_conv:\n",
        "    if msg['role'] == 'user':\n",
        "        print(f\"Q: {msg['content']}\")\n",
        "    elif msg['role'] == 'assistant':\n",
        "        print(f\"A: {msg['content'][:300]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚ú® Notice the step-by-step reasoning in the enhanced version!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "exp4_cell_compare"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üì• Download Your Dataset\n",
        "\n",
        "Download the files to your local machine:"
      ],
      "metadata": {
        "id": "download_files_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a zip file with all outputs\n",
        "!zip -r llama3_dataset.zip data/final/\n",
        "\n",
        "print(\"‚úÖ Dataset packaged!\")\n",
        "print(\"\\nüì¶ Download 'llama3_dataset.zip' from the Files panel (left sidebar)\")\n",
        "print(\"   Or run this cell and click the download link below:\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('llama3_dataset.zip')"
      ],
      "metadata": {
        "id": "download_files_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üéì Workshop Complete!\n",
        "\n",
        "## What You Accomplished:\n",
        "\n",
        "‚úÖ **Parsed** a research paper automatically (to .txt format)  \n",
        "‚úÖ **Generated** 50+ Q&A pairs using Cerebras with custom prompts  \n",
        "‚úÖ **Filtered** for quality using LLM-as-judge with custom rating criteria  \n",
        "‚úÖ **Exported** to multiple training formats  \n",
        "‚úÖ **Learned** advanced features (CoT, chunking, thresholds, custom prompts)  \n",
        "\n",
        "## üöÄ Next Steps:\n",
        "\n",
        "1. **Try your own PDFs** - Upload any research paper or document\n",
        "2. **Customize prompts** - Edit the prompts in the config for your domain\n",
        "3. **Adjust parameters** - Experiment with thresholds, chunk sizes, etc.\n",
        "4. **Fine-tune a model** - Use your dataset with Transformers/Axolotl\n",
        "5. **Scale up** - Process entire directories of documents\n",
        "\n",
        "## üìö Resources:\n",
        "\n",
        "- **Toolkit:** https://github.com/meta-llama/synthetic-data-kit\n",
        "- **Cerebras API:** https://cerebras.ai/\n",
        "- **Documentation:** Check the toolkit README for advanced features\n",
        "\n",
        "---\n",
        "\n",
        "**üéâ Happy Dataset Building!**"
      ],
      "metadata": {
        "id": "conclusion_section"
      }
    }
  ]
}